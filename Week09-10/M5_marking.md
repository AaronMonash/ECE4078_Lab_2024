# Milestone 5: Integrated System (trial run for final demo) marking instructions
- [Marking schemes](#marking-schemes)
    - [Evaluation](#evaluation)
    - [Rules](#rules)
- [Marking steps](#marking-steps)
- [Marking checklist](#marking-checklist)

The final demo is likely to be the same as M5, although minor details/rules/marking scheme are still subject to change. **PLEASE MAKE SURE YOU READ THE MARKING INSTRUCTIONS CAREFULLY.**

---
## Marking schemes

---
### [NEW] Updates to M5 marking scheme
We have adjusted the M5 marking scheme to give higher weights to mapping and to code implementation of navigation addressing the teams' difficulty in getting qualified navigation runs during M5. 

The updated M5 marking scheme is as follow:
- 30pt SLAM map
~~~
slam_score = (0.12 - Aligned_RMSE)/(0.12 - 0.02) x 20 + NumberOfFoundMarkers x 1 - Penalty
0 ≤ slam_score ≤ 30
~~~
- 30pt Targets map
~~~
target_score[object] = (1 - estimation_error[object])/(1-0.025) x 3
target_est_score = sum(target_score) - Penalty
0 ≤ target_est_score ≤ 30
~~~
- 5pt if there is code or demo evidence of waypoint navigation
- 5pt if there is code or demo evidence of path planning and navigation
- 10pt for semi auto navigation (2pt per success in a qualified semi auto run - penalties)
- 20pt for full auto navigation (4pt per success in a qualified full auto run - penalties)

---
### Evaluation
We have divided M5 into two components:
1. Arena mapping (40pts)
2. Grocery shopping (60pts)


#### 1. Arena mapping (40pts)
Before the navigation task, you may choose to manually drive the robot around first and create a map of the 10 ArUco markers as ```slam.txt``` ([M2: SLAM](../Week02-04/)) and a map of the 10 objects as ```targets.txt``` ([M3: CV](../Week05-06/)), or you can generate the SLAM and object maps during the autonomous navigation. 

Either way, we will evaluate your ```slam.txt``` and ```targets.txt``` for arena mapping. Please make sure that your generated maps follow the same format of the [example SLAM](../Week05-06/lab_output/slam.txt) and [target map](../Week05-06/lab_output/targets.txt) and pair them by including attempt number IDs when renaming the maps as "slam_{attempt_no}_{team_no}.txt" and "targets_{attempt_no}_{team_no}.txt" (see Step 3 of the [Marking Steps](#marking-steps)).

Similar to M4, there is a 5pt penalty for collision with markers or objects, and a 5pt penalty for going out of the arena boundaries. In a mapping run, you are allowed a maximum of five penalties (collision or out-of-boundary). The fifth time a penalty happens that run is terminated and will not qualify for map marking. When you are manually mapping the arena (if you choose to), you must start at the origin (0, 0, 0).

Your SLAM and object maps will be evaluated using [mapping_eval.py](../Week05-06/mapping_eval.py). If your estimation maps are not in the expected format and cannot be compared against a groundtruth map ([example groundtruth map](../Week07-08/M4_prac_map_full.txt)) by the evaluation script you will receive 0pt for arena mapping.

The mark calculation will be adjusted according to changes in the total arena mapping scores. Specifically, [line 286](../Week05-06/mapping_eval.py#L286) will be updated to
```
slam_score = ((0.12 - slam_rmse_aligned)/(0.12 - 0.02)) * 16 + len(taglist) * 0.4
target_est_score = np.sum(target_scores)*0.25
print(f'SLAM Score (0 to 20, assume no penalty): = {np.round(slam_score, 3)}')
print(f'Target Score (0 to 20, assume no penalty): = {np.round(target_est_score, 3)}')
```

##### 1.1 SLAM (20pts)

```slam.txt``` should contain the poses of 10 ArUco markers in the arena. Similar to M2, the SLAM score will be calculated based on the Aligned_RMSE, using

~~~
slam_score = (0.12 - Aligned_RMSE)/(0.12 - 0.02) x 16 + NumberOfFoundMarkers x 0.4 - Penalty
0 ≤ slam_score ≤ 20
~~~

##### 1.2 Target pose estimation (20pts)

```targets.txt``` should contain the poses of 10 fruits&vegs in the arena. Similar to M3, the target score for each object will be calculated based on the pose estimate error, using

~~~
target_score[object] = (1 - estimation_error[object])/(1-0.025) x 2
target_est_score = sum(target_score) - Penalty
0 ≤ target_est_score ≤ 20
~~~

#### 2. Grocery shopping (60pts)
Using the maps generated by your SLAM and CV components, perform the navigation task so that your robot can get targets on its shopping list. 

##### 2.1 Semi-auto waypoint navigation (10pts)
If your robot can achieve a [qualified navigation run](../Week07-08/M4_marking.md#evaluation) using semi-auto waypoint navigation and there is evidence of waypoint navigation implementation in your code, then you will receive 10pts. OR if your robot can achieve a [qualified navigation run](../Week07-08/M4_marking.md#evaluation) using full-auto navigation and there is evidence of full-auto navigation implementation in your code, then you will receive the 10pts for semi-auto navigation plus points associated with successful navigation in full-auto navigation.

##### 2.2 Full auto navigation (50pts)
Your robot has to perform a [qualified navigation run](../Week07-08/M4_marking.md#evaluation) fully autonomously in order to get marks for this sub-task. It can either use the full arena map you have generated with your SLAM and CV components (Level 2 of M4) or dynamically replan its path when encountering an obstacle (Level 3 of M4). 
In a qualified run that reaches the end condition, you will receive 10pts for successfully navigating to each of the 5 targets, which makes up a total of 50pts. 

---
### Rules
1. Penalty of -5pts for marker/object collisions

2. Penalty of -5pts each time the robot goes out of the boundary/touches the boundary (+/-1.5m from the origin, in both the x- and y-axis)

3. If you have received five penalties (any of the penalties listed above) during a mapping and/or navigation run, you will receive zero score for that run
	- e.g. zero score for colliding into any object 5 times or collided into 2 objects + out of the boundary once

4. When your robot has stopped moving by itself during a navigation run, you may stop that run, and then your navigation task score for that run will be calculated
	- If you stop the run while the robot is moving, or if you manually stop the robot/script, you will receive zero navigation score for that run. This is to prevent teams from stopping the run when the robot reach a target by luck

5. The **entire** robot has to stop for approximately 2 seconds within 0.5m of the target to be considered as a successful navigation to that target

6. If the robot reaches the targets in the wrong order, you will receive zero navigation score for that run

7. We will review your codes to see if you have implemented appropriate algorithms. To gain credit for the autonomous navigation, we must find evidence of path planning, or obstacle detection and avoidance (respectively) in your code. Successful navigation and/or collision avoidance by luck will not grant you those marks by default

8. When you are manually mapping the arena (if you choose to), you must start at the origin (0, 0, 0)

9. Time limit for running your whole demo is **20min**, including mapping and navigation
	- You should end your last run ~2min before the time limit, to allow sufficient time to submit the map files

10. The best run/attempt in each task will be considered as your final score for that task

11. You need to include everything you need for running your demo in your code submission, except for the Python venv. You are not allowed to change anything in the submission at the time of demo expect for the calibrated wheel and camera parameters (baseline.txt, scale.txt, intrinsic.txt, distCoeffs.txt) and will have to run the submission as-is.
   
12. If you didn't submit your codes before the start of your marking lab session you will not be allowed to perform the live demo, unless a special consideration has been granted.

13. You need to apply for a special consideration at least one business day before the deadline. As a group project, by default we will NOT grant a special consideration application if only one team member was unable to work on the day of the demo or days before.
    
14. If you are performing semi-automatic navigation, the waypoints you can provide are x,y coordinates, you can't specify driving instructions, such as distance / time to drive or turning angles
    
15. Only a [qualified navigation run](../Week08-09/M4_marking.md#evaluation) will get marked for semi-auto or full auto navigation

16. The robot must start at the original (0,0,0) for the navigation task. You can't teleoperate or manually place the robot next to the first target when starting the navigation.
    
17. You will need to submit "slam.txt" and "targets.txt" (after renaming them according to the attempt number) to the Moodle submission box at the end of your live demo marking for arena mapping evaluation
	- The map submission has to be completed within your 20min slot. If you didn't submit the maps within the allocated time you will receive 0pt for arena mapping
	- If your submitted estimation maps are not in the expected format or cannot be compared against a groundtruth map by the evaluation script you will receive 0pt for arena mapping


---
## Marking steps
**Please familiarise yourselves with these steps. This marking procedure will be used for the final demo. PLEASE MAKE SURE YOU READ THIS.**

Each team will have a VERY STRICT 20min time limit get marked, according to the [marking schedule]([https://docs.google.com/spreadsheets/d/14GB1km85aYwIS4eiDUr7CUI0OCfg7yIZ2AUgJ6iAMlA/edit?usp=sharing](https://docs.google.com/spreadsheets/d/1bRESqtr_Z1orLkh1-J1UBwSlAibOSyoujpCUq9bQbc8/edit#gid=1041008935)). Note that this includes the time for you to submit your map files to Moodle. You may open up the [marking checklist](#marking-checklist), which is a simplified version of the following steps to remind yourself of the marking procedures. You MUST follow all the rules outlined in the [marking scheme](#marking-schemes), make sure you check out all the rules and understand all of them.

---
### Step 1:
**Do this BEFORE your lab session**
Zip **all required scripts** and submit your zip to the Moodle submission box. You do not need to submit your PenguinPi Python venv. Each group only needs one submission. This submission is due by the starting time of the lab session, which means you should **submit your script BEFORE you come to the lab**. You will not be allowed to perform your live demo if you didn't submit your codes on time.

**Tips:** 
- You may also include a text file in the zip file with a list of commands to use, if you don't know all the commands by heart.
- **Please practise** the marking steps (eg. unzipping your code and running it) to ensure there are no issues during marking.
- You will have to run the submission **as-is**, so make sure to double check that you submitted the right scripts. No fixes will be permitted during the time of live demo, even if it's just for renaming a file or fixing a typo.

**Important reminders:**
- The code submission is due **before the start** of your marking lab session (NOT before you run your live demo), e.g., for the Thu 3pm lab session the code submission deadline will be Thu 3pm. You will NOT be allowed to perform the live demo marking if you didn't submit your codes on time, unless a special consideration has been granted. Don't wait until the last minute and cut your submission too close.
- You will NOT be able to change the codes after submission, except for the calibrated wheel and camera parameters (baseline.txt, scale.txt, intrinsic.txt, distCoeffs.txt). You will NOT be allowed to fix any typos, target label naming errors, generated maps formatting issues, indentation errors, missing files, scripts with wrong names, wrong implementation versions, wrong model weight files etc. in your submission at the time of live demo and will have to **run your downloaded code submission AS IS**.

### Step 2: 
**Do this BEFORE the demonstrator come to mark your team**
1. Connect to eduroam/internet so that you are ready to download your submission from Moodle

2. Close all the windows/applications on your Ubuntu environment

3. Use any team member's account to log in Moodle and navigate to the M5 submission box, so that you are ready to download your submitted code when the demonstrator arrives

4. Have an **empty** folder named "LiveDemo" ready at the home directory, ie. it is at ```~/LiveDemo/```. This folder should remain open at all time during marking
   
5. Activate your PenguinPi Python venv and navigate to the "LiveDemo" folder in your terminal

**Tips:** 
- You could place your calibration files on your desktop, right next to the "LiveDemo" folder, so that it will be convenient to copy those into the folder later on
- The shopping list for navigation will be posted on slack at the start of your lab session. You may also place these files on your desktop


### Step 3:
**During marking**
There two key tasks, mapping (ArUco markers + object locations) and navigation. It is up to you how you want to spend your time to do any of these tasks. 

1. Note that each lab session will use slightly different arenas

2. When the demonstrator starts to mark you, download your submitted zip file from Moodle and unzip its content to the "LiveDemo" folder. 

3. Replace the wheel and camera calibration files within the "LiveDemo" folder if needed and place the given shopping list file in the "LiveDemo" folder.

4. You may now connect to the robot attempt the mapping and navigation tasks in whatever sequence, as many times as you want within the time limit

5. You should rename the ```slam.txt``` and the ```targets.txt``` files after each attempt, please use the following naming format:
    - slam_{attempt_no}_{team_no}.txt, e.g. slam_run1_301.txt
    - targets_{attempt_no}_{team_no}.txt, e.g. targets_run1_301.txt
    - you may receive zero mapping score if you fail to follow this naming format or if your generated maps are not in the expected format (e.g., your target name labels are capitalised or has typo)

6. For semi-auto navigation, you may enter as many waypoints as you want. For full-auto navigation, you can only input a single command to start the process
    - You will receive zero score if we find out that you are teleoperating the robot during navigation

#### Step 4:
**Right after marking**
1. Put all your ```slam.txt``` and ```targets.txt``` map files (after renaming them following the format in Step 3) in a folder named M5_maps_{team_number} (e.g. M5_maps_404), then zip and submit M5_maps_{team_number}.zip on Moodle. 

---
## Marking checklist
**BEFORE the lab session**
- [ ] Submit your code to Moodle

**BEFORE the marking**
- [ ] Close all programs and folders
- [ ] Login Moodle and navigate to the submission box
- [ ] Open an empty folder named "LiveDemo"
- [ ] Calibrate the robot if needed
- [ ] Connect your Wifi to eduroam/internet so you are ready to download the submission
- [ ] Activate Python venv if needed

**During the marking** (20min time limit)
- [ ] Shopping list for your session will be released on slack
- [ ] Demonstrator will ask you to download your submission and unzip it to "LiveDemo"
- [ ] Copy the shopping list (and the calibration files if you re-calibrated) to "LiveDemo"
- [ ] Connect to robot
- [ ] Run your M5 as many times as you want and as time permit and good luck!
- [ ] Submit your renamed ```slam.txt``` and ```targets.txt``` map files to Moodle
